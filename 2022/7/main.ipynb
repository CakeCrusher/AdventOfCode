{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### PLAN\n",
    "- create a tree node\n",
    "- build the tree\n",
    "  - keep track of path by storing a node list\n",
    "  - nodes will contain: name, children, size\n",
    "  - fill nodes with the immediate size\n",
    "- traverse the tree\n",
    "  - use DFS to aggregate to the total_size through the worst case\n",
    "\n",
    "### Discoveries\n",
    "- Multiple dirs can share the same name\n",
    "- Sooooo thats why you use slashes in OS directory trees...\n",
    "  - makes each path unique and is easily parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1428881\n"
     ]
    }
   ],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "        self.dir_name = val.split(\" \")[-1]\n",
    "        self.size = 0\n",
    "        self.children = {}\n",
    "\n",
    "with open('input.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "def build_tree(lines):\n",
    "    current_path = []\n",
    "    current_path_str = \"\"\n",
    "    nodes = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        # will ignore \"$ ls\"\n",
    "        if line.startswith(\"$\"):\n",
    "            if line.startswith(\"$ cd\"):\n",
    "                # print(current_path_str)\n",
    "                if line.endswith(\"..\\n\"):\n",
    "                    dir_node = current_path.pop()\n",
    "                    current_path_str = current_path_str[:-(len(dir_node.dir_name) + 1)]\n",
    "\n",
    "                else:\n",
    "                    dir_name = line[5:-1]\n",
    "                    current_path_str += \" \"+dir_name\n",
    "                    if (current_path_str not in nodes):\n",
    "                        nodes[current_path_str] = TreeNode(current_path_str)\n",
    "                    current_path.append(nodes[current_path_str])\n",
    "        # files and dirs\n",
    "        else:\n",
    "            if line.startswith(\"dir\"):\n",
    "                dir_name = line[4:-1]\n",
    "                temp_dir_str = current_path_str + \" \" + dir_name\n",
    "                if (temp_dir_str not in nodes):\n",
    "                    nodes[temp_dir_str] = TreeNode(temp_dir_str)\n",
    "                current_path[-1].children[temp_dir_str] = nodes[temp_dir_str]\n",
    "            else:\n",
    "                file_size = int(line.split(\" \")[0])\n",
    "                current_path[-1].size += file_size\n",
    "    return nodes\n",
    "\n",
    "def dfs(node, visited=set()):\n",
    "    # print(\"PRE: \", node.val, node.size)\n",
    "    for child in node.children.values():\n",
    "        # # to avoid cycles\n",
    "        # if child not in visited:\n",
    "            # visited.add(child)\n",
    "        node.size += dfs(child, visited)\n",
    "    # print(\"POST: \", node.val, node.size)\n",
    "    return node.size\n",
    "\n",
    "def conditioned_result(nodes):\n",
    "    sum_sizes = 0\n",
    "    for node in nodes.values():\n",
    "        if node.size < 100000:\n",
    "            sum_sizes += node.size\n",
    "    return sum_sizes\n",
    "\n",
    "def pipeline1(lines):\n",
    "    nodes = build_tree(lines)\n",
    "    # for node in nodes.values():\n",
    "    #     print(node.val, node.size)\n",
    "    root = nodes[\" /\"]\n",
    "    dfs(root)\n",
    "    return conditioned_result(nodes)\n",
    "\n",
    "\n",
    "print(pipeline1(lines))\n",
    "# NOT: 1167625, 1440660 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "- calculate space needed to be freed\n",
    "- iterate through nodes and find the one whose size is the smallest amount more than the space needed to be freed\n",
    "  - could use a binary search tree for optimization (but after spending 2 hours on part 1, I'm not doing that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " / jsv bwc jwrhclh 10475598\n",
      "10475598\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "def conditioned_result_part2(nodes):\n",
    "    root = nodes[\" /\"]\n",
    "    disk_space = 70000000\n",
    "    free_space_required = 30000000\n",
    "    free_space = disk_space - root.size\n",
    "    amt_to_free = free_space_required - free_space\n",
    "    \n",
    "    top_candidate = None\n",
    "    for node in nodes.values():\n",
    "        if node.size > amt_to_free and (top_candidate is None or node.size < top_candidate.size):\n",
    "            top_candidate = node\n",
    "    print(top_candidate.val, top_candidate.size)\n",
    "    return top_candidate.size\n",
    "        \n",
    "\n",
    "def pipeline2(lines):\n",
    "    nodes = build_tree(lines)\n",
    "    # for node in nodes.values():\n",
    "    #     print(node.val, node.size)\n",
    "    root = nodes[\" /\"]\n",
    "    dfs(root)\n",
    "    \n",
    "    return conditioned_result_part2(nodes)\n",
    "\n",
    "\n",
    "print(pipeline2(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy solution (from being tired and rushed) dont look ðŸ™ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173873\n"
     ]
    }
   ],
   "source": [
    "# MESSY solution\n",
    "# this is the result of a rushed attempt\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "with open('input.txt') as f:\n",
    "    lines = f.readlines()\n",
    "tree = {}\n",
    "current_path = []\n",
    "hash_space = defaultdict()\n",
    "paths_str = []\n",
    "paths = []\n",
    "inserts = defaultdict(set)\n",
    "\n",
    "dirs = set()\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    if (line.startswith(\"$ cd\")):\n",
    "        if (line[5:-1] == \"..\"):\n",
    "            # remove the first element\n",
    "            current_path.pop()\n",
    "        else:\n",
    "            # add to the first position\n",
    "            dirs.add(line[5:-1])\n",
    "            current_path.append(line[5:-1])\n",
    "            # current_path.insert(0, line[5:-1])\n",
    "        # navigate the tre\n",
    "        if (str(current_path[:]) not in paths_str):\n",
    "            paths_str.append(str(current_path[:]))\n",
    "            paths.append(current_path[:])\n",
    "\n",
    "for path in paths:\n",
    "    for idx, dir in enumerate(path):\n",
    "        if (idx < len(path) - 1):\n",
    "            inserts[dir].add(path[idx + 1])\n",
    "\n",
    "sizes = defaultdict(int)\n",
    "for dir in dirs:\n",
    "    size = 0\n",
    "    is_dir = False\n",
    "    is_files = False\n",
    "    for line in lines:\n",
    "        # print(line)\n",
    "        if (line.startswith(\"$ cd \" + dir)):\n",
    "            is_dir = True\n",
    "        elif (line.startswith(\"$ ls\")):\n",
    "            is_files = True\n",
    "        elif (not line.startswith(\"$\") and is_dir and is_files):\n",
    "            try:\n",
    "                size += int(line.split(\" \")[0])\n",
    "            except:\n",
    "                pass\n",
    "        elif (line.startswith(\"$ cd \")):\n",
    "            is_dir = False\n",
    "            is_files = False\n",
    "        elif (line.startswith(\"$\") and is_dir and is_files):\n",
    "            break\n",
    "    sizes[dir] = size\n",
    "# print(inserts)\n",
    "# print(dirs)\n",
    "# print(sizes)\n",
    "\n",
    "def dfs(dir,navigated = []):\n",
    "    navigated.append(dir)\n",
    "    size = sizes[dir]\n",
    "    if dir in inserts:\n",
    "        for insert in inserts[dir]:\n",
    "            if insert not in navigated:\n",
    "                size += dfs(insert)\n",
    "    return size\n",
    "# print(dfs(\"jqmgn\"))\n",
    "# print(dirs)\n",
    "sum_sizes = 0\n",
    "for dir in list(dirs):\n",
    "    t_size = dfs(dir)\n",
    "    if (t_size < 100000):\n",
    "        sum_sizes += t_size\n",
    "print(sum_sizes)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$ cd /\\n',\n",
       " '$ ls\\n',\n",
       " 'dir a\\n',\n",
       " '14848514 b.txt\\n',\n",
       " '8504156 c.dat\\n',\n",
       " 'dir d\\n',\n",
       " '$ cd a\\n',\n",
       " '$ ls\\n',\n",
       " 'dir e\\n',\n",
       " '29116 f\\n',\n",
       " '2557 g\\n',\n",
       " '62596 h.lst\\n',\n",
       " '$ cd e\\n',\n",
       " '$ ls\\n',\n",
       " '584 i\\n',\n",
       " '$ cd ..\\n',\n",
       " '$ cd ..\\n',\n",
       " '$ cd d\\n',\n",
       " '$ ls\\n',\n",
       " '4060174 j\\n',\n",
       " '8033020 d.log\\n',\n",
       " '5626152 d.ext\\n',\n",
       " '7214296 k']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pipeline(lines):\n",
    "    return lines\n",
    "pipeline(lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ebb0fa82196ab5cd02a5b231fa8fb6d37dc58c342ef6ac8d3ed2447e0dae4a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
